---
layout: post
title:  "Reactive Websites with SSE (and HTTP/2)"
date:   2020-09-26 22:36:20 +0100
categories: posts
---

I was wondering how to build a reactive website and use [Server Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events) (SSE) over [HTTP/2](https://en.wikipedia.org/wiki/HTTP/2) to push updates to the browser, and implement it with [Netty](https://netty.io/). The events could be anything. I was thinking about sending virtual memory statistics to the client.

You might ask, what is so special about reactive websites? Reactive websites are really cool and exciting. They make me think like something is happening - something important perhaps - and immediately tell me about it. Also, these are cool applications to build.

Two good examples of modern reactive and interactive websites are [Slack](https://slack.com/) who make a decent business from sending messages between browsers, and [Grafana](https://grafana.com/) which is a dashboard application displaying real-time metrics such as you might find on a TV screen overshadowing your friendly neighbourhood development team. Who wants to refresh the browser for updates? Death to F5 and CTRL+R.

The plan is going to be:

1. Generating events
1. Bootstrap and start Netty
1. The client view
1. Subscribing to events

Before exploring some code, let's briefly review the options.

### Polling, WebSockets and SSE

The simplest is probably a bit of Javascript in the browser which periodically polls the webserver for updates. It is actually a wonderful approach because it utilises plain old web technologies, however it can be a bit spammy to the webserver and may incur the cost of reconnections. This cost is mitigated in browsers with connection pools, [persistent TCP connections](https://en.wikipedia.org/wiki/HTTP_persistent_connection) and HTTP/2.

The other popular option is opening a [WebSocket](https://en.wikipedia.org/wiki/WebSocket) both send and receive messages. It is the most powerful option and there is good support for it. However, you have to think about [security](https://christian-schneider.net/CrossSiteWebSocketHijacking.html#main), [authentication](https://www.freecodecamp.org/news/how-to-secure-your-websocket-connections-d0be0996c556/) and implementing a messaging protocol, e.g. [STOMP](http://jmesnil.net/stomp-websocket/doc/). It is a good choice for an FX trading application.

You might wonder what is so special about Server Sent Events. As a primer, there is a very good rundown of SSE at [Ably.io](https://www.ably.io/topic/server-sent-events). I think SSE is great because is it based on the HTTP protocol which means great support in browsers for reconnection and resuming. Events are just simple text messages. 

There are a couple of downsides of SSE.

1. After the client sends the initial HTTP request, the channel becomes half-duplex and only the server may send data along the TCP connection. To send more data to the server, a client must then initiate a new request. Not a problem if you're building a dashboard web application.

1. There is an even bigger, [Fatberg](https://en.wikipedia.org/wiki/Fatberg) of a downside. Browsers generally need to limit the number of connections to the same host and port to six. That also means a maximum of six SSE connections open. Imagine the case of six tabs open to a particular webpage, and then the seventh, eighth and ninth tab pages simply sit there doing nothing. No errors. Nothing.

This is where HTTP/2 walks into the room looking smug, and opens all the windows to allow in the fresh air. HTTP/2 multiplexes any number of streams over a single TCP connection. So, now you can have as many tabs as you eat.
 
So far we have SSE and HTTP/2 but what about Netty when there is [Reactor Netty](https://projectreactor.io/docs/netty/release/reference/index.html#_http2) and [Vertx](https://github.com/aesteve/vertx-sse/blob/master/src/main/java/io/vertx/ext/web/handler/sse/impl/EventSourceImpl.java), or even [Spring](https://dzone.com/articles/server-sent-events-using-spring)? I thought it would be more fun and challenging learning Netty directly. 

### Generating Events

Linux has a system utility called `vmstat` which reports virtual memory statistics to the console. It is a good example of some changing data on my Linux workstation that I can push directly to a browser. 

Let's see what vmstat looks like for the next 3 seconds:

```
$ vmstat --wide --timestamp 1 3
procs -----------------------memory---------------------- ---swap-- -----io---- -system-- --------cpu-------- -----timestamp-----
 r  b         swpd         free         buff        cache   si   so    bi    bo   in   cs  us  sy  id  wa  st                 BST
 0  0         9472     29826444      3043784     22607868    0    0     8    20    9    9   4   1  95   0   0 2020-09-25 08:53:48
 0  0         9472     29826948      3043788     22607972    0    0     0    24 3840 5695   1   0  99   0   0 2020-09-25 08:53:49
 0  0         9472     29826948      3043788     22607976    0    0     0     0 4315 8180   0   0 100   0   0 2020-09-25 08:53:50
```

We could take each row and push it to the browser as is, perhaps with a long-running vmstat process, spawned by the webserver, which prints an update every second. Instead, we are going to read and parse output so that the webserver understands that data and can perform things like filtering or sending changed values only.

These lines can be more easily parsed if we switch to using the `--stats` option. The display for stats does not repeat, so we will need to schedule this inside the application.

```
$ vmstat --stats --unit=k 
     67357312 k total memory
     10684957 k used memory
     25727972 k active memory
      6882492 k inactive memory
     30414192 k free memory
      3119513 k buffer memory
     23138652 k swap cache
     33806088 k total swap
         9699 k used swap
     33796388 k free swap
      9392227 non-nice user cpu ticks
       394162 nice user cpu ticks
      2769121 system cpu ticks
    236951499 idle cpu ticks
        94913 IO-wait cpu ticks
       353581 IRQ cpu ticks
       328286 softirq cpu ticks
            0 stolen cpu ticks
     20597490 pages paged in
     49735331 pages paged out
          146 pages swapped in
         2316 pages swapped out
   1384535934 interrupts
   2447764979 CPU context switches
   1600932061 boot time
       594245 forks
```

We will read each attribute into a VmstatEvent and push that to a handler of subscriptions and notifications to connected sessions. 

```java
public class VmstatEvent {
    public final long timestampMillis;
    public final long totalMemoryKb;
    public final long idleCpuTicks;
    // contructor ...
}

class VmstatService {
    void start() {
        vmstatsExecutor.scheduleAtFixedRate(() -> {
                VmstatEvent vmstatEvent = vmstatRunner.getVmstat();
                eventsPublisher.offer(new Data(vmstatEvent));
           }, 
           0, 2, SECONDS); // run now, and every 2 seconds
    }
}
```

The SSE stream of virtual memory statistics, with timestamp, total memory and idle CPU ticks serialised into a JSON blob of data.

```bash
$ curl -k https://localhost:8443/vmstat

event: message
id: 0
data: {"timestampMillis":1601045544232,"totalMemoryKb":67357312,"idleCpuTicks":296942791}

event: message
id: 1
data: {"timestampMillis":1601045546231,"totalMemoryKb":67357312,"idleCpuTicks":296947921}

event: message
id: 2
data: {"timestampMillis":1601045548230,"totalMemoryKb":67357312,"idleCpuTicks":296953334}
```

In browsers which support SSE, the `EventSource` class is available in Javascript to request events. Instead of print these to the console log, we could modify the page DOM directly or have Javascript view library do it for us, e.g. Vue.js.

```javascript
const evtSource = new EventSource('https://localhost:8443/vmstat');    
evtSource.onmessage = function(event) {
    console.log("message: " + event.data);
};
```

### Netty and HTTP/2

Netty supports HTTP/2 and is used by projects such as Vertx and Spring Reactor Netty, but the Netty documentation in this area is a bit weak. Despite this, the Netty source contains some insightful examples about how to handle HTTP and HTTP/2 traffic in a webserver.

HTTP/2 can be either encrypted or unencrypted but most modern browsers make encryption mandatory (<https://www.mnot.net/blog/2015/06/15/http2_implementation_status>). In a production deployment configuration, you may choose to deploy a front proxy with TSL/SSL pass-through using [Envoy](https://www.envoyproxy.io), and it also supports HTTP/2 endpoints. However, it is way more exciting to do this within the application using Netty and it makes testing and deployment on a developer workstation easier.

Assuming encryption really is the way forward, the application will need to understand and negotiate the HTTP protocol because now there is HTTP/2 which has frames and streams. Application-Layer Protocol Negotiation (ALPN) is an extension of Transport Layer Security (TLS) that allows the application negotiate which HTTP protocol to use, such as HTTP 1.1 or HTTP 2. This stage happens after the TLS handshake has been completed and without needing any further communication to the client.

Netty has a composable approach, using pipeline, to handle the different layers and protocols, including SSL, ALPN, HTTP/2 stream multiplexing and eventually request handling. 

The pipelines are going to look like this:

*Inbound*

```
[SSL] --> [ALPN] --> [HTTPCodec] --> [FallbackRequestHandler]
            |
            v    
       [HTTP2FrameCodec] --> [Multiplexer] --> [StreamToHttpCodec] -> [RequestHandler]
```

*Outbound*

```
[SSL] <-- [HTTPCodec] <-- [FallbackRequestHandler]

[SSL] <-- [HTTP2FrameCodec] <-- [Multiplexer] <-- [StreamToHttpCodec] <-- [RequestHandler]
```

Now we have that out the way, let's see what it looks like in Java.

## Secure HTTP2 Server

Here the `start()` method creates and starts the server, binding it to a host and port, and configuring it so every channel has:

 1. The SSL context which performs the TLS handshake, followed by
 2. The Http2/Http1 protocol negotiation handler (which also handles HTTP requests)

```java
class SecureHttp2Server {
    void start() {
        final SslContext sslCtx = configureTLS();

        final ServerBootstrap b = new ServerBootstrap();
        b.option(ChannelOption.SO_BACKLOG, 1024);
        b.group(group);
        b.channel(NioServerSocketChannel.class);
        b.handler(new LoggingHandler(SecureHttp2Server.class, LogLevel.DEBUG));
        b.childHandler(new ChannelInitializer<SocketChannel>() {
            @Override
            protected void initChannel(SocketChannel ch) {
                ch.pipeline().addLast(
                        sslCtx.newHandler(ch.alloc()),
                        new CloseOnExceptionHandler(),
                        new Http2OrHttp1NegotiationHandler(router));
            }
        });

        final Channel ch = b
            .bind(socketAddress.getAddress(), socketAddress.getPort())
            .sync() // await bind to complete
            .channel();
    } 
}
```

Now, we need negotiate protocol with the client and build the appropriate pipeline. When configuring HTTP/2 we use `Http2FrameCodec` and `Http2MultiplexHandler` handlers to piece together HTTP/2 frames and multiplex streams arriving at the same connection. Each stream ultimately needs a pipeline instance and channel. If you happen to share the same pipeline for all streams as I did, then strange things happen and any stream can receive any other's payload of data. 

```java
class Http2OrHttp1NegotiationHandler extends ApplicationProtocolNegotiationHandler {
    // ...
    @Override
    protected void configurePipeline(ChannelHandlerContext ctx, String protocol) {
        if (HTTP_2.equals(protocol)) {
            configureHttp2(ctx, router);
        } else if (HTTP_1_1.equals(protocol)) {
            configureHttp1(ctx);
        } else {
            throw new IllegalStateException("unknown protocol: " + protocol);
        }
    }

    private static void configureHttp1(ChannelHandlerContext ctx) {
        ctx.pipeline().addLast(
                new HttpServerCodec(),
                new HttpObjectAggregator(MAX_CONTENT_LENGTH),
                new FallbackRequestHandler());
    }

    private static void configureHttp2(ChannelHandlerContext ctx, Router router) {
        final ChannelPipeline p = ctx.pipeline();
        // decode http2 frames
        p.addLast(Http2FrameCodecBuilder.forServer().build());

        // direct streams to pipelines
        p.addLast(new Http2MultiplexHandler(new ChannelInitializer<Channel>() {
            @Override
            protected void initChannel(Channel ch) {
                // each HTTP/2 stream is allocated a channel and pipeline to handle requests
                ch.pipeline().addLast(
                        new Http2StreamFrameToHttpObjectCodec(true, false),
                        new Http2RequestHandler(router));
            }
        }));
    }
}
```

That was a lot to get through. What is the client side view of HTTP2?

### Client

It is useful to see what the server is doing from the response we receive in the client. Luckily, `curl` reveals the TLS handshake, ALPN negotiation and HTTP protocol messages with the `--verbose` option enabled. Use the `--insecure` option here to allow self-signed certificates.

```
$ curl --verbose --insecure https://localhost:8443/vmstat
...
* Connected to localhost (127.0.0.1) port 8443 (#0)
```

*Establish TLS*

```
* ALPN, offering h2
* ALPN, offering http/1.1
... TLS handshake...
* SSL connection using TLSv1.3 / TLS_AES_128_GCM_SHA256
```

*ALPN confirms HTTP2*

```
* ALPN, server accepted to use h2
... cert info...
* Using HTTP2, server supports multi-use
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0
* Using Stream ID: 1 (easy handle 0x5635b718cb10)
```

*Send the HTTP/2 request*

```
> GET /vmstat HTTP/2
> Host: localhost:8443
> user-agent: curl/7.69.1
> accept: */*
> 
... TLS info...
```

*Recieve a HTTP/2 response as an SSE even-stream*

```
< HTTP/2 200 
< content-type: text/event-stream; charset=UTF-8
< cache-control: no-cache
< access-control-allow-origin: *
< 
```

### Subscriptions and Event Notifications

When an HTTP request arrives for an SSE resource the webserver needs to reply with an HTTP response with a couple of important headers. They were seen in the `curl` command previously. 

* `content-type: text/event-stream` // server sent events
* `connection: keep-alive` // persistent TCP connection

To respond to SSE requests, the HTTP/2 SSE 'request' handler will need to

1. Apply the request stream to the response
1. Set HTTP response headers
1. Send the response to the client
1. Do not close the channel but instead use it to subscribe to future messages

Netty lends a hand by providing helper classes to access the response and request objects.

```java
class VmstatSseRequestHandler {
    // maps to GET: "/vmstat"
    void handle(ChannelHandlerContext ctx, FullHttpRequest request) {
        DefaultHttpResponse response = new DefaultHttpResponse(HTTP_1_1, OK);
        HttpHeaders headers = response.headers();

        // HTTP/2 stream id
        String streamId = request.headers().get(STREAM_ID.text());
        if (null != streamId) {
            headers.set(STREAM_ID.text(), streamId);
        }

        headers.set("Content-Type", "text/event-stream; charset=UTF-8");
        headers.set("Connection", "keep-alive");
        headers.set("Cache-Control", "no-cache");
        headers.set("Access-Control-Allow-Origin", "*");
        ctx.writeAndFlush(response);

        // unsubscribe on close            
        ctx.channel().closeFuture().addListener(f -> channelSubscriber.unsubscribe(ctx.channel()));

        // notify StatsEventHandler
        channelSubscriber.subscribe(ctx.channel());
    }
}
```

Then notify the `StatsEventHandler` about this new subscription channel. The handler will write SSE event messages to this channel and the channels of all other subscribers.

```java
class StatsEventHandler {   
    // ... events store, registered subscribers, etc
    void onSubscription(Subscribe subscribe) {
        subscribers.add(subscribe.subscriberId);
        vmstatEvents.forEach(data -> publish(subscribe.subscriberId, data));
    }
    
    void onUnsubscription(Unsubscribe unsubscribe) {
        subscribers.remove(unsubscribe.subscriberId);
    }

    void onData(Data data) {
        VmstatEvent vmstatEvent = data.vmstatEvent;
        String message = MessageFormat.format(
                "event: message\n" +
                "id: {0}\n" +
                "data: {1}\n\n",
                cnt++, toJson(vmstatEvent));

        vmstatEvents.addLast(message);
        if (vmstatEvents.size() > eventsCapacity) {
            vmstatEvents.removeFirst();
        }

        subscribers.forEach(id -> publish(id, message));
    }

    void publish(ChannelId id, String data) {
        channels.close(cm -> !cm.isWritable()).sync();
        if (channels.isEmpty()) {
            return;
        }
    
        Channel channel = channels.find(id);
        if (channel == null) {
            return;
        }
    
        // wrap the payload in a DefaultHttpContent
        final ByteBuf content = ByteBufAllocator.DEFAULT.buffer();
        content.writeBytes(data.getBytes(UTF_8));
        channel.writeAndFlush(new DefaultHttpContent(content));
    }
}
```

This event handler is running continually on a thread, waiting for messages on a `BlockingQueue<Event>`, assuming threads can be spared. Be careful not to use the Netty thread pools for this purpose, to avoid deadlocks or thread starvation.

```java
class StatsEventService {
    void start() {
        executor.execute(() -> {
                while (true) statsEventHandler.handle(eventQueue.take());
            });
    }
}
```

### Summary

Netty is super powerful, when you find the instruction manual. You can use it to build a webserver that sends Server Sent Events over HTTP/2, and we only touched the surface.

Keeping the number of third party Java dependencies to a minimum has some awesome benefits, and implementing a webserver from scratch with just Netty is immensely rewarding. Still, I would recommend Vertx or Spring Reactor for most production use cases, simply because they offer a reactive interface that neatly hides away the bare metal implementation details of Netty. That is okay for most people.

Further topics I may explore in a later blog include how to handle backpressure, or the case of a slow consumer, and browser reconnection and resuming.
